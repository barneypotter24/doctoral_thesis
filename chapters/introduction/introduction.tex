% !TeX root = ../../thesis.tex
\chapter{General Introduction}\label{ch:introduction}

\begin{minipage}[b]{0.6\textwidth}
  \includegraphics[width=\textwidth]{title} % Note: image is 695 X 1,181 pixels
\end{minipage}
\hfill
\begin{minipage}[b]{0.35\textwidth}
  \begin{flushright}
    \footnotesize
    \textit{``A measure of wisdom | each man shall have,\\
    But never too much\\let him know;\\
    For the wise man's heart | is seldom happy,\\
    If wisdom too great he has won.''} \\
    --- \textit{H\'avam\'al}, 55 
  \end{flushright}
  \vspace{2cm}
\end{minipage}

\clearpage

\onehalfspacing

All living things exist in a constant state of conflict with the biological agents that exploit them in the arena of evolution.
Since the advent of civilization humans have sought an upper-hand in this biological arms race: we harvest the flora and fauna that surround us through agriculture and domestication to our benefit, and we fiercely seek to defeat the plants, animals, and disease-causing pathogens that would do us harm.
While we have largely found means to overcome the challenges of our natural environment to lengthen and improve our lives, the eradication of parasites, bacteria, and viruses remains one of the great challenges facing mankind.
Indeed, as the human population grows and urbanizes we become increasingly vulnerable to new diseases more rapidly than ever before.
Concurrent with the exponential growth and globalization of humans is a demand for increased quality of living; which in turn necessitates the human colonization of natural environments that were previously uninhabited by humans in search of land and resources.
This intrusion into environments puts us into greater contact with animals that host diseases that our species has never before encountered, leading to an ever-increasing risk of emerging infectious diseases (\gls{eid}s) jumping from their natural reservoir into human beings, and spreading at unprecedented speeds through their new susceptible hosts.
Perhaps the greatest of these threats is that posed by viruses.

Viruses are the root cause of some of the \gls{eid}s that have caused the most human suffering and death over the last hundred years.
They have been responsible for outbreaks that have affected local regions (e.g. Ebola virus in central and western Africa \& MERS-CoV in the Arabian peninsula) to epidemics that can seasonally threaten large portions of the globe (e.g. Dengue virus, RSV, and West Nile Virus) to pandemics of global scale that threaten all people (e.g. seasonal influenza viruses, \gls{hiv}, and \gls{sarscov2}).
In fact, viruses have been responsible for all major pandemics since the year 1900: six major influenza pandemics (ranging from the 1918 Spanish flu to the 2009 H1N1pdm09 ``swine flu''), the \gls{hiv}/AIDS pandemic beginning in 1981, and the COVID-19 pandemic.
Viruses also have some of the greatest future pandemic potential due to their ubiquity and fast-mutating nature.

Fortunately, global public health efforts have made increasingly effective strides toward understanding and eliminating viral pathogens, perhaps most famously by eradicating smallpox through a global vaccination campaign ending in the 1980s.
A crucial step in the fight against viral pathogens has been the development of clinical and statistical methodologies that link the outcomes of viral epidemics (case counts, mortality rates, etc.) to the underlying determinants of pathogen spread that drive the epidemic---a field of study known as \textbf{epidemiology}.
While traditional epidemiology has provided invaluable insights, the advent of molecular techniques and the ever decreasing cost of full-genome sequencing has revolutionized our understanding of viral dynamics.
This dissertation illustrates three use cases of how these molecular data can be integrated with traditional epidemiological methods---with a particular focus on \gls{sarscov2} and hepatitis B virus---demonstrating the broad applicability of these techniques in understanding and combating viral epidemics across several different clinically-important time scales.

% 1.1
% NOTE to Guy&Mandev: This section is a bit flowery, but my intention is to get the reader thinking about the interplay of viruses and time
% since that "phylodynamics at time scales" idea is the through-thread of my dissertation
\section{Viral epidemics}\label{sec:int-viralEpi}
Viral epidemics have shaped human history for millennia, leaving their mark on societies and civilizations throughout the ages.
These microscopic pathogens demonstrate an unparalleled ability to spread rapidly through populations, causing widespread illness, death, and social disruption.
From ancient times to the modern era, viruses have been silent yet powerful actors in the drama of human existence, influencing demographics, economies, and even the outcomes of wars.

The historical record is filled with examples of devastation caused by viral epidemics.
In the \nth{5} century BCE, the Plague of Athens decimated the population the eponymous city-state, altering the course of the Peloponnesian War \citep{thucydides1972history}.
Modern-day analysis suggests that this plague may have been caused by a viral hemorrhagic fever \citep{olson1996thucydides}.
The globalization of human movement over the ensuing centuries facilitated the spread of viral pathogens across continents, leading to the emergence of pandemics that reshaped the course of human history.
The arrival of smallpox in the Americas in the \nth{16} century had catastrophic consequences for indigenous populations, facilitating European colonization and reshaping the New World's demographic landscape.
More recently still, the 1918 influenza pandemic, which claimed an estimated 50 million lives worldwide, stands as a stark reminder of the potential for viral pathogens to cause global calamity.

Up to the present, viral epidemics continue to pose significant challenges to global public health and socioeconomic stability.
The \gls{hiv}/AIDS pandemic, first recognized in the early 1980s, has claimed millions of lives and continues to affect communities worldwide.
The emergence of novel coronaviruses, including SARS in 2003 and \gls{sarscov2} in 2019, has demonstrated the ongoing threat of emerging viruses and their potential to rapidly spread in our interconnected world.
As humans continue to expand our built environment into previously uninhabited regions of the planet, we increase the likelihood of zoonotic (animal derived) spillover events, with pathogens such as avian influenza viruses, animal coronaviruses, or poxviruses currently posed as potential threats to future human health if we do not make efforts to hinder their potential jumps into the human population.
These events underscore the critical importance of understanding viral pathogens, their mechanisms of transmission, and their evolution to effectively combat future epidemics and minimize their impact on human society.

\subsection{Epidemics and pandemics}\label{sec:epidemicsVsPandemics}
The ensuing chapters of this dissertation will explore the evolutionary dynamics of viral pathogens across different spatiotemporal scales.
Before delving into the specifics of these analyses, it is helpful to define the terms ``epidemic'' and ``pandemic,'' and to outline the key distinctions between these two related concepts.

An \textbf{epidemic} refers to the occurrence of a disease that exhibits a frequency clearly in excess of normal expectancy within a specific community, geographical area, or season.
Epidemics are characterized by the rapid spread of disease across a particular population or region.
The threshold for declaring an epidemic is context-dependent, taking into account factors such as the pathogen's baseline prevalence, population susceptibility, and local health infrastructure.
Epidemics can vary in scale and duration, ranging from localized outbreaks affecting a single community to more widespread occurrences that impact multiple regions within a country or neighboring nations.

In contrast, a \textbf{pandemic} represents a more extensive and severe form of epidemic, typically characterized by the global spread of a novel pathogen or a new strain of an existing pathogen to which the human population has little to no preexisting immunity.
Pandemics transcend international boundaries, often affecting multiple continents simultaneously and causing sustained community-level outbreaks.
The declaration of a pandemic by health authorities, such as the World Health Organization, considers not only the geographical extent of disease spread but also the severity of the illness and its societal impact.
Pandemics often result in significant morbidity and mortality on a global scale, strain healthcare systems worldwide, and can lead to severe socioeconomic disruptions across affected regions.

In this dissertation, I focus on the evolutionary dynamics of \gls{sarscov2} and hepatitis B virus, two viral pathogens that have had a profound impact on human health and society, however the analyses presented herein consider such dynamics in \textit{specific contexts}.
The coronavirus disease 2019 (COVID-19) pandemic, caused by \gls{sarscov2}, was declared to be a pandemic by the World Health Organization on 11 March 2020 \citep{healthorganization2020coronavirus}, however the analyses described in Chapter~\ref{ch:chapter1} and Chapter~\ref{ch:chapter2} explore the phylodynamics of only the early COVID-19 epidemic in Belgium, and the Omicron epidemic in Pakistan, respectively.
The results of these analyses therefore cannot be extrapolated to the global dynamics of the COVID-19 pandemic as a whole.
Chapter~\ref{ch:chapter3} explores the evolutionary history of hepatitis B virus, which is not considered to be an epidemic or pandemic in the traditional, but is rather endemic to the human population in most of the world.

\subsection{Traditional and genomic epidemiology}\label{sec:tradVsGenEpi}
The field of epidemiology has long been concerned with understanding the spread of infectious diseases and the factors that influence their transmission.
Traditional epidemiological methods, such as contact tracing, case reporting, and mathematical modeling, have been instrumental in controlling outbreaks and informing public health interventions for hundreds---if not thousands---of years.
One of the earliest examples of epidemiological investigation dates back to a 1854 cholera outbreak in the West End of London, where Dr. John Snow correlated counts of cholera cases at different addresses to nearby water sources.
By making such a correlation, he was able to identify a contaminated water pump on Broad Street as the putative source of the epidemic (Fig.~\ref{fig:broadStreetPump}).

\begin{figure}[ht]
  \centering
  \includegraphics[width=.6\textwidth]{broad_street_pump}
  \caption[John Snow's map of the 1854 Broad Street cholera outbreak in London]{John Snow's characterization of the 1854 London cholera outbreak is considered epidemiology's foundational moment. Snow incorporated the geographic locations (addresses) of Snow's map of the outbreak, which showed a cluster of cases around the Broad Street pump, illustrates the process that led him to conclude that the pump was the source of the outbreak. \textit{Figure credit: John Snow, 1854} \citep{snow1854mode}.}
  \label{fig:broadStreetPump}
\end{figure}

In the years since Snow's pioneering work, epidemiology has evolved into a multidisciplinary field that combines elements of medicine, public health, statistics, and social science to study and determinants of health and disease in populations.
Epidemiological methods have been instrumental in controlling infectious diseases, identifying risk factors for disease transmission, and evaluating the effectiveness of public health interventions.
Indeed, as technology and data collection methods have advanced, epidemiologists have been able to develop increasingly sophisticated models of how diseases spread.

At the core of most epidemiological models lie three main data components: identified infections, locations, and times.
These three basic components can be combined in a number of ways to build more complex descriptions of disease spread (e.g. epidemic curves, spatial maps of disease incidence, etc.).
Both on their own and combined with other sources (patient demography, clinical interventions and outcomes, etc.), these data can be input into extremely robust models that can be used to not only retrospectively describe epidemics, but also to make predictions about future spread that can be used to inform public health policy.

However, following the discovery of the structure of DNA by Rosalind Franklin, James Watson, and Francis Crick in 1953 \citep{franklin1953molecular,watson1953molecular}, the field of epidemiology has been revolutionized by the advent of molecular techniques.
The addition of molecular data gave epidemiologists a newfound ability to not just analyze the disease outcomes that are can be observed in a population, but also to analyze the biological agents directly responsible for the epidemics.
The field was further revolutionized in 1976, with the first full-genome sequence of a virus \citep{fiers1976complete}.
As sequencing technology has become more advanced and less expensive, we now have the ability to obtain full-genome sequences of viral pathogens from hundreds or thousands of infected individuals in a single outbreak, allowing us to compare genetic sequences (Fig.~\ref{fig:alignment}) through an assortment of methodologies.
When these methods are applied to pathogen outbreaks in an effort to understand the dynamics of the pathogen and inform public heath interventions, we refer to them collectively by the name of \textbf{genomic epidemiology} \citep{armstrong2019pathogen,black2024applied}.

Though there are parallels between them---and they often address similar underlying biological questions---traditional epidemiology and genomic epidemiology represent complementary approaches to understanding disease spread and dynamics, each offering distinct insights into public health challenges.
While both methodologies seek to understand patterns of disease occurrence and transmission, they differ fundamentally both their primary units of analysis, and in their ultimate research goals.
Traditional epidemiology focuses on infected individuals and population-level health outcomes, examining factors such as disease incidence, prevalence, mortality rates, and risk factors---these methods can be applied to both infectious and non-infectious diseases.
It has a long history of helping researchers and public health officials understand disease burden, identify vulnerable populations, and implement public-health interventions.
By contrast, genomic epidemiology focuses on the heritable characteristics of disease-causing pathogens themselves.
By examining the genetic signatures of pathogens as they spread through populations, genomic epidemiology can help us to better understand transmission chains, identify the emergence of novel variants, and to track the evolution of virulence or drug resistance---questions that may be difficult or impossible to address through traditional epidemiological approaches alone.

\begin{figure}[ht]
  \centering
  \begin{subfigure}{0.95\textwidth}
    \includegraphics[width=\textwidth]{unaligned}
    \caption{}
  \end{subfigure}
  \begin{subfigure}{0.95\textwidth}
    \includegraphics[width=\textwidth]{aligned}
    \caption{}
  \end{subfigure}
  \caption[Multiple sequence alignment]{A set of five example genomic sequences viewed both \textit{(a)} prior to alignment, and \textit{(b)} after being aligned using MAFFT \citep{katoh2013mafft} and visualized using AliView \citep{larsson2014aliview}; each row represents a single sequence, and each column represents a site shared between sequences. Sites are colored by the amino acid present in each sequence at each site. The sequence \textit{Example2} represents the most common type of mutation that we observe: single nucleotide polymorphisms (\gls{snp}s), where a single sequence has a single mutation from one amino acid to another. Examples 3--5 represent other types of genomic motifs that are frequently observed, but not always explicitly modeled by phylogenetic inference algorithms.}
  \label{fig:alignment}
\end{figure}

While there are many different ways that researchers can leverage the information carried in pathogens' genomes to better understand their epidemiological dynamics, this thesis will focus in particular on those dynamics that relate to \textit{shared evolutionary history} of a set of genomic sequences---each representing an individual infected by a virus at a given point in time.
Broadly, our goal is to model evolutionary processes that causes observable differences in pathogen genomes (e.g. Fig.~\ref{fig:alignment}) to hypothesize the patterns of evolution that led to the sequence data that we observe.
We refer to these inferred hypotheses of shared evolutionary history as \textbf{phylogenies}, and the field of research related to their inference as \textbf{phylogenetics}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.85\textwidth]{genSizeVsMutRate}
  \caption[Genome size vs. mutation rate in viruses.]{It an established phenomenon that as genome size and complexity increases, observed mutation (and evolutionary) rates decrease. For viruses in particular, this has the practical upshot that it means that genomic mutations accumulate frequently enough that they can be found during epidemic timescales. \textit{Figure credit: Duffy, Shackleton, \& Holmes (2008)} \citep{duffy2008rates}.}
  \label{fig:sizeVsRates}
\end{figure}

While it is interesting---and frequently useful---to understand the evolutionary relationships between viral sequences, the inferences made through phylogenetic analysis can tell us much more when we contextualize them in \textit{time} and \textit{space}.
Viruses (and in particular \gls{rna} viruses) accumulate genomic mutations at a staggering rate compared to many other domains of biological entities (Fig.~\ref{fig:sizeVsRates}).
Because of this, we are frequently able to make observations (i.e. collect sequences) of viruses over the same time scales that epidemics play out, and make phylogenetic inferences on the same time scales.
We refer to this merger of phylogenetic and epidemic time scales as \textbf{phylodynamics}.
When viral genomes also come with associate geographic metadata, we are able to make further inferences (either in sequence or jointly with the phylogeny) of where common ancestors of taxa likely existed, and the associated rates of migration between the sampled locations.
This process of combined spatiotemporal and evolutionary inference will be referred from here on as \textbf{phylogeography}.
These concepts are illustrated in Figure~\ref{fig:phylogeneticsOverview}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.85\textwidth]{rambautFig}
  \caption[Applications of phylodynamics]{Fundamental concepts in phylodynamic analysis. a) Rooted, bifurcating phylogenetic tree derived from (viral) genomic sequences, branch lengths (here shown on the vertical axis) represent observed genetic distance. b) Time-calibrated phylogenetic tree demonstrating the phylodynamic relationship between genetic distance and time. Branch lengths now represent time. c) Mutations take place along the tree's branches, with mutations that become fixed falling on the backbone tree's (blue) versus those on terminal branches (black) which are not yet fixed in a subpopulation. d) Discrete phylogeographic inference hypothesizes the history of pathogen spread. Branches are annotated by inferred geographic locations. e) Underlying pathogen population structure influences tree shapes. When we consider a tree drawn from a population that varies in size through time, we observe different patters of branching patterns and branch lengths.
  \textit{Figure credit: Pybus \& Rambaut (2009)} \citep{pybus2009evolutionary}.
  }
  \label{fig:phylogeneticsOverview}
\end{figure}

\subsection{A general model of the epidemic process}
In the pursuit of descriptive models for pathogen evolution and spread, it is important to ask, ``Is this model a faithful description of my biological question?''
To answer this question, it is necessary to construct a high-level framework of this biological system (i.e. epidemic spread), and to recognize the assumptions inherent to that framework.
To this end, a brief description of the epidemic process as seen through the lens of phylogenetics is required so that we can answer the question, ``Do molecular phylogenies accurately describe viral epidemics?''

At the beginning of an epidemic, we imagine that there is a single individual who is infected by a virus, and they remain infectious for some limited period of time (either they will recover to the point of no longer being infectious, or die).
During their infectious period, the individual may go on to infect one or more other individuals with the virus (Fig.~\ref{fig:epiProcess}a).
This process is then able to repeat itself for each of the infected individuals, and in turn for individuals infected downstream.
Generally, if on average each infected person spreads the virus to more than one new person the epidemic will grow, and if they spread to fewer than one person on average then the epidemic will shrink.
At some point---or in practice at many points---during the downstream epidemic, individuals may be sampled and a complete viral genomic sequence may be isolated from the individual (Fig.~\ref{fig:epiProcess}b).

Each genome will be similar though slightly different from one other, and the degree to which they differ will be in proportional to how deep in the transmission history the two sequences differ.
Put differently, we expect sequences to be similar in proportion to the amount of evolutionary history that they share (Fig.~\ref{fig:epiProcess}c).
In this model, we assume that transmission events represent a complete (or complete-enough) and instantaneous bottleneck on the population, and that each individual can be represented by a single consensus genomic sequence.
We also assume that evolution takes place independently along each branch of the tree---that is, mutations that occur along one branch of the phylogeny have no affect on the other branches.

\begin{figure}[ht]
  \centering
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{epi2}
    \label{fig:epiProcess1}
    \caption{}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{epi5}
    \label{fig:epiProcess2}
    \caption{}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{epi6}
    \label{fig:epiProcess3}
    \caption{}
  \end{subfigure}
  \caption[The epidemic process is inherently treelike]{\textit{(a)} an individual with an infectious period indicated by a solid horizontal line; dashed vertical line indicates an instantaneous infection event. \textit{(b)} Downstream in the epidemic, subsequently infected people are sampled, and genomic sequences are generated from their infecting virus. Viruses that are more closely related (e.g. the two green sequences at the bottom of the tree) have sequences that are more similar to each other than to more distantly related sequences. \textit{(c)} Statistical modeling of the similarities in viral sequences allows us to reconstruct a hypothesis of the shared evolutionary history that links the sequences.}
  \label{fig:epiProcess}
\end{figure}

\subsection{Genomic epidemiology across spatiotemporal scales}
This thesis will explore three different applications of genomic epidemiology to three different cases, each representing a distinctly different temporal scope.
Each of these cases addresses one of the main uses of phylodynamic methodologies: Chapter~\ref{ch:chapter1} concerns real-time public health-facing phylodynamics, Chapter~\ref{ch:chapter2} uses phylogeography in a \textit{post hoc} manner to understand the ongoing dynamics of a viral epidemic, and Chapter~\ref{ch:chapter3} extends this framework to investigate the long-term dynamics of a virus that has been in the human population for thousands of years.

\subsubsection{Real-time genomic epidemiology}
The first time scale---explored in Chapter~\ref{ch:chapter1}---is the real-time phylodynamic analysis of \gls{sarscov2} in Belgium, with a focus on the period between September 2020 and November 2022.
These early stages of the COVID-19 pandemic presented both the necessary use-case, as well as the unprecedented data stream to facilitate the use of genomic sequence data as a a near-weekly informant to the public policy making process.
To this end, a herculean effort was made by the global scientific community to establish routine genomic surveillance \citep{smith2020integrated,deng2020genomic,tegally2022evolving}, develop laboratory and bioinformatic methods \citep{wang2020establishment,tyson2020improvements,chiara2021next}, and create tools to facilitate the efficient and accurate analysis of a previously unheard of quantity of genomic sequence data \citep{shu2017gisaid,minh2020iq,aksamentov2021nextclade}.

During this time, many researchers were tasked with helping their state, federal, and regional governments understand SARS-CoV-2 transmission dynamics so that targeted interventions could be implemented in a timely manner.
Belgium represents just one such case out of many throughout the globe.
In particular, in these early stages of the pandemic we sought to identify epidemiologically linked outbreak clusters, to detect cryptic transmission chains, and to distinguish between within-Belgium transmission and introductions from other countries.
These inferences were necessary to give evidentiary support to targeted intervention strategies, such as adjusting travel restrictions, allocating testing resources, and modifying contact tracing protocols.
Furthermore, these real-time phylogeographic analysis allowed the Belgian health authorities to monitor the arrival and spread of variants of concern (\gls{voc}s), as each emerged.
Chapter~\ref{ch:chapter1} represents just one part of the national effort to use genomic surveillance on a semi-weekly basis to curb the intensity of the Belgian COVID-19 epidemic.

\subsubsection{\textit{Post hoc} genomic epidemiology}
Chapter~\ref{ch:chapter2} explores the most common use-case of genomic epidemiology---a \textit{post hoc} analysis of a specific epidemic that both describes the individual epidemic and simultaneously provides insights of current public-health concern.
\bip{come back to this section and the next}

\subsubsection{Paleogenomic epidemiology}


% 1.2
\section{Viruses discussed in this thesis}
While the methodologies used in this thesis have applications to most (if not all) pathogenic viruses, we will focus on the analysis of two: \gls{sarscov2} and \gls{hbv}.
Both are responsible for significant burden of disease in humans, however the two have very different virology, epidemiology, and evolutionary characteristics.
Even though a complete understanding of these characteristics is not necessary to understand this thesis, some high-level background may nonetheless be helpful for contextualizing why these two viruses are suitable to demonstrate the multi-temporal utility of genomic epidemiology.

\subsection{SARS-CoV-2}
The first virus discussed in this thesis is \textbf{severe acute respiratory syndrome coronavirus 2} (\gls{sarscov2}), the causative agent of coronavirus disease 2019 (COVID-19).
\gls{sarscov2} is a \textit{Betacoronavirus} first observed in the human population in late-2019.
It is very closely related to the previously observed SARS-CoV and MERS-CoV---responsible for the 2002--2004 severe acute respiratory syndrome and Middle Eastern respiratory syndrome of the 2010's, respectively \cite{gorbalenya2020species}.
    
Careful readers may notice discrepancies in names---particularly in sequence IDs for \gls{sarscov2}.
This is a result of shifting nomenclature used during the early stages of the COVID-19 pandemic, resulting in cases where ``ncov'' (novel coronavirus) or ``hCoV-19'' (human coronavirus 2019) are used and may appear in figures or associated code repositories.
These are only differences in name, and should be mistaken as biologically relevant distinctions.

\subsubsection{COVID-19 Pandemic}
Contemporary readers of this thesis will require no introduction to the COVID-19 pandemic, however, a quick overview will still be given for potential future readers.

The first reported cases of an atypical pneumonia was first noted in Wuhan, Hebei, China, in December 2019 \citep{zhou2020pneumonia}.
This outbreak of atypical pneumonia was promptly identified as a novel coronavirus \citep{wu2020new}.
Within three months, the virus had globalized \cite{dong2020interactive}, leading the World Health Organization to declare a global pandemic on March 11, 2020 \cite{healthorganization2020coronavirus}.

Between 2020 and 2023, the COVID-19 pandemic demonstrated repeated resurgences, with successive waves driven by the emergence of novel variants.
This ultimately resulted in over 770 million reported cases and over 7\,000\,000 confirmed deaths \citep{ourworldindata-covid-explorer}.
The pandemic's impact extended far beyond direct health outcomes, resulting in unprecedented economic and social upheaval.
The COVID-19 pandemic also triggered public health measures across the globe such as lockdowns, border closures, and mask mandates.
The pandemic officially ended in May 2023, however \gls{sarscov2} has now become endemic in the human population and continues to circulate.

\subsubsection{SARS-CoV-2 virology and genome}
\gls{sarscov2} has a long, \gls{pssrna} genome of approximately 30\,000 nucleotides which encodes four structural proteins across six \gls{orf}s.
Of these, the S (spike) protein is under the most intense selective pressure; it is the viral surface glycoprotein (Fig.~\ref{fig:sarscov2micrograph}) that both mediates viral entry into host cells \citep{zhu2021molecular}, and is the primary target of neutralizing antibodies created by the human immune system \citep{v2021coronavirus}.
\gls{sarscov2}'s primary mode of cellular entry is through the binding of the viral spike protein to the human angiotensin converting enzyme 2 (ACE2).

\begin{figure}[ht]
  \centering
  \includegraphics[width=.55\textwidth]{sarscov2micrograph}
  \caption[SARS-CoV-2 electron micrograph]{Transmission electron micrograph of a SARS-CoV-2 virus particle (UK B.1.1.7 variant), isolated from a patient sample and cultivated in cell culture. The prominent projections (green) seen on the outside of the virus particle (yellow) are spike proteins. This fringe of proteins enables the virus to attach to and infect host cells and then replicate. Image captured at the NIAID Integrated Research Facility (IRF) in Fort Detrick, Maryland.
  \textit{Figure and caption credit: NIAID}.
  }
  \label{fig:sarscov2micrograph}
\end{figure}

While the spike gene is typically considered to be under the most selective pressure, for phylogenetic analyses we will consider the entire 30kb viral genome.
\gls{sarscov2} is estimated to have a mutation rate of $1\times10^{-6}$--$2\times10^{-6}$ mutations per site per replication cycle, leading to an overall evolutionary rate of approximately $1\times10^{-3}$ substitutions per site per year, though this rate differs slightly by variant \citep{markov2023evolution}.

\subsubsection{Variants of concern}
Both the evolution and epidemiology of \gls{sarscov2} have been characterized largely by the emergence and spread of novel variants.
As the virus evolved and spread, different ``branches'' acquired mutations that resulted in variable viral fitness (Fig.~\ref{fig:sarscov2phylo}).
The most successful of these variants demonstrated enhanced transmission capabilities, immune escape properties, or both, leading to their designation by the World Health Organization as variants of concern (\gls{voc}s).
These \gls{voc}s---beginning with Alpha (first detected in the United Kingdom) in late 2020 and continuing through multiple Omicron sublineages---have repeatedly reshaped the pandemic by outcompeting their predecessors and triggering new waves of infection, even in populations who had previously achieved high levels of immunity due to infection and/or vaccination.
With very few exceptions, each novel \gls{voc} has completely outcompeted the preexisting variants, thereby driving the previous lineage to extinction (Fig.~\ref{fig:sarscov2phylo}, bottom panel).

\begin{figure}[ht]
  \centering
  \begin{subfigure}{0.9\textwidth}
    \includegraphics[width=\textwidth]{sarscov2phylogeny}
  \end{subfigure}
  \begin{subfigure}{0.9\textwidth}
    \includegraphics[width=\textwidth]{sarscov2freqs}
  \end{subfigure}
  \caption[SARS-CoV-2 phylogeny and variant frequencies]{Overview of \gls{sarscov2} variants over the course of the pandemic. \textit{(top)} Global, time-calibrated phylogenetic tree of \gls{sarscov2} sequences colored by variant spanning from the beginning of the pandemic until the present. \textit{(bottom)} estimated variant frequency plot spanning the same time period. \textit{Figure credit: nextstrain.org} \citep{hadfield2018nextstrain} (accessed 2 November 2024).}
  \label{fig:sarscov2phylo}
\end{figure}

The complexities of SARS-CoV-2 evolution demanded multiple systems for naming and tracking viral lineages.
The World Health Organization developed a simplified Greek alphabet naming system (e.g., Alpha, Delta, Omicron) for variants of concern, providing an accessible vocabulary for public health communications and media reporting.
However, more detailed classification systems were needed for scientific purposes.
The Pango nomenclature system \citep{o2021assignment,o2022pango}, which has become the \textit{de facto} standard for SARS-CoV-2 classification, uses an alphanumeric hierarchy to designate lineages (e.g., B.1.1.7, JN.1), with new levels added as the virus diversifies.
Complementing these approaches, the Nextstrain \citep{hadfield2018nextstrain,aksamentov2021nextclade} nomenclature system provides broader evolutionary context by grouping viruses into major clades (e.g., 19A, 20I) based on defining mutations.
While the WHO system names only variants with significant public health impact, these technical classification systems together provide the detailed framework necessary for tracking the full diversity of SARS-CoV-2 evolution.
A (partial) mapping between these different nomenclature systems is noted in Table~\ref{tab:variants}.
For this thesis, Pango lineages will be used primarily, however occasionally the WHO designation will also be provided.

\begin{table}[]
  \begin{tabular}{llll}
  \hline
  \textbf{WHO} & \textbf{Pango lineage} & \textbf{Nextstrain lineage} & \textbf{Time of origin} \\ \hline
  Alpha        & B.1.1.7                & 20I                         & September 2020          \\
  Beta         & B.1.351                & 20H                         & September 2020          \\
  Gamma        & P.1                    & 20J                         & September 2020          \\
  Delta        & B.1.617.2/AY           & 21A/21J                     & March 2021              \\
  Omicron      & B.1.1.529/BA/\ldots    & 21M/21F/24A/\ldots          & September 2021          \\
  \end{tabular}
  \caption{\gls{sarscov2} VOC designations, and their associated Pango and Nextstrain lineage designations. Note that there is not always an exact one-to-one correspondence as these systems use slightly different features to define distinct lineages.}
  \label{tab:variants}
\end{table}

\subsubsection{Biological and epidemiological questions}
This thesis focuses on two primary types of analysis of \gls{sarscov2}: real-time and \textit{post hoc} epidemiological settings.
Each of these settings leads to different fundamental questions that we try to answer using the tools of phylodynamic inference.

The primary questions that motivate the work shown Chapter~\ref{ch:chapter1} were those of immediate public health concern during the early--mid COVID-19 epidemic in Belgium.
These questions were primarily motivated by three situations. 
The first situation concerns specific clusters of sequences requiring investigation.
These cases arise in situations when there were a set of infections in a group of epidemiologically linked individuals---for example Belgian military personnel returning from overseas \citep{pirnay2020study} or a cluster of infected students\citep{vanelslande2022two}---where we sought to understand if the cluster of cases were epidemiologically linked to each other, represented sources of viral introduction into the country, or posed an risk of driving onward transmission chains that could be prevented.
The second major situation we encountered took place when globally emergent \gls{sarscov2} lineages needed to be characterized within Belgium.
In these cases, either because of the emergence of \gls{VOC} lineages, or lineages that harbored \gls{voc}-like mutations \cite{dudas2021emergence}, public health officials sought our assistance in understanding whether the variants had reached Belgium, were driving an increased count in cases, and represented an urgent public health concern withing the country.
The final important line of inquiry during this time concerned sequences generated through Belgium's routine genomic surveillance program.
Over the course of the pandemic, Belgium sequenced a substantial fraction of \gls{pcr}-positive samples.
As a result, we were able to rapidly incorporate these sequences into the existing context of the Belgian \gls{sarscov2} epidemic, and we were thereby able to understand the relative growth or decline of variants, and characterize the within-Belgium distribution of sequences.

The second major analytical framework explored in this thesis, presented in Chapter~\ref{ch:chapter2}, demonstrates how phylodynamic methods can be applied retrospectively to understand historical patterns of viral spread, focusing on the emergence of the BA.1 Omicron variant in Pakistan.
Through Bayesian phylogeographic reconstruction, we investigated the timing and frequency of BA.1 introductions into Pakistan, mapping the variant's spread from its global emergence to its establishment within the country.
Such \textit{post hoc} analyses address fundamentally different questions than real-time surveillance, focusing on broader evolutionary and epidemiological patterns that emerge over time.
By reconstructing these historical dynamics, we can better understand how viral variants establish themselves in new geographic regions, and identify major routes of viral movement.
These insights, while not immediately applicable to public health response, are crucial for improving our understanding of \gls{sarscov2} spread at a global scale and informing future pandemic preparedness efforts.

\subsection{Hepatitis B Virus (HBV)}
The second virus analyzed in this thesis is hepatitis B virus (\gls{hbv}), a orthohepadnavirus spread through human bodily fluids.
Hepatitis B virus (and its eponymous disease), are of significant global public health concern, causing nearly 300 million ongoing chronic cases of hepatitis B, as well as nearly one million deaths every year \citep{revill2020evolution}.
In addition to its direct disease consequences, \gls{hbv} is also a primary driver of the liver cancer hepatocellular carcinoma (\gls{hcc}).
Hepatitis B virus is characterized by several genotypes that are genetically distinct, and drive differences in both virulence and response to treatment.
Because \gls{hbv} differs from \gls{sarscov2} in many ways---having an extremely different epidemiology, genome, and history in the human population---it presents an ideal system to demonstrate the utility of phylodynamic analysis over long time scales.

\subsubsection{An ancient human pathogen}
In stark contrast to \gls{sarscov2}, \gls{hbv} has been in the human population for an extremely long time.
Recent estimates of the time of the most recent common ancestor (\gls{tmrca}) by \citet{kocher2021ten} suggest that the virus has circulated in the human population for upwards of ten thousand years (Fig.~\ref{fig:hbvFullTree}).
This long evolutionary history means that HBV's early diversification and spread occurred during periods of dramatically different human population dynamics---before the advent of widespread agriculture, let alone the interconnected world we now live in. 
One of the important results of this is that \gls{hbv} has a strong ethnospatial distribution throughout the globe (Fig.~\ref{fig:hbvDist}), as its historical dispersal has relied on the mobility of humans.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.55\textwidth]{full-hbv-tree}
  \caption[Phylogeny of all HBV genotypes]{Time-calibrated phylogeny of \gls{hbv} illustrating inferred evolutionary relationships between all genotypes. The inferred \gls{tmrca} suggests that \gls{hbv} has been in the human population for many thousands of years. \textit{Figure credit: Kocher et al. (2021)} \citep{kocher2021ten}.
  }
  \label{fig:hbvFullTree}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=.85\textwidth]{hbv-dist}
  \caption[Global distribution of hepatitis B virus]{Map illustrating the global distribution of \gls{hbv} genotypes. This thesis focuses on genotypes A, D, and E.
  \textit{Figure credit: Sunbul (2014)} \citep{sunbul2014hepatitis}.
  }
  \label{fig:hbvDist}
\end{figure}

\subsubsection{HBV genome}
Hepatitis B virus has a unique genomic architecture that impacts phylogenetic analysis significantly (Fig.~\ref{fig:hbvGenome}).
\gls{hbv} has a circular, partially double-stranded \gls{dna} (ds\gls{dna}) genome, with a a long strand approximately 3\,000 nucleotides in length, and a short strand of roughly 2\,200 nucleotides.
With such a small and compact genome, \gls{hbv} has evolved to contain multiple overlapping reading frames along the genome.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.45\textwidth]{hbv_genome_schematic}
  \caption[Schematic of the hepatitis B virus genome]{\bip{CAPTION} \textit{Figure credit: \bip{credit!} (2021)} \citep{kocher2021ten}.
  }
  \label{fig:hbvGenome}
\end{figure}

\paragraph*{Oops, no temporal signal!}
The combination of these features---having a \gls{dna} genome rather than \gls{rna}, and overlapping \gls{orf}s---put a very strong purifying selective pressure on \gls{hbv}'s genome.
Not only does ds\gls{dna} have an inherent error-correction mechanism, but any mutation that does arise has multiple opportunities to be deleterious.
This resistance to mutation accumulation results in a virus that not only has a very small genome, but also accumulates mutations at a reduced rate.
As a consequence, it is very difficult to derive an evolutionary rate estimate from a sample of contemporary \gls{hbv} genomes (referred to as weak \textit{temporal signal}, further described in Section~\ref{ssec:molClock}).
Weak temporal signal means that it is very difficult to confidently estimate the timing of historical events in \gls{hbv}'s ancestry.

Fortunately, we are able to circumvent this issue in part by leveraging \gls{hbv}'s long history in the human population.
Recently, researchers such as \citet{muhlemann2018ancient} have been able to extract and sequence viral \gls{dna} found in well-preserved mummies, allowing us to incorporate a small number of ancient genomes into our phylodynamic analysis, some upwards of four-thousand years old.
By including these genomes we are able to inject our analysis of contemporary genomes with enough temporal information to make inference about the timing of past events.

\subsubsection{Biological and epidemiological questions}
Chapter~\ref{ch:chapter3} investigates questions relating to the patterns of global dispersal of three \gls{hbv} genotypes: A, D, and E.
These three genotypes have recently been found in patients who have immigrated to Belgium, where there is low \gls{hbv} endemicity, and the genotypes are not typically associated.
Understanding the contemporary patterns of spread for individual \gls{hbv} genotypes is important for the treatment and control of \gls{hbv} in particular because of the historical spatial distribution of the genotypes and the fact that the genotypes have different virulence and responses to treatments.
Because different locations will likely have established treatment programs tailored to their local \gls{hbv} genotypes it is crucial to understand the patterns of viral dispersal that could lead such local treatment options less effective than they had previously been.

%1.3
\section{Phylodynamics and phylogeography}
The primary methods by which this thesis addresses the biological questions posed in the previous section fall into the domain of phylodynamic inference.
These methodologies leverage statistical models of genetic sequence evolution, evolutionary rates, geographic dispersal, and population structures to reconstruct hypotheses of evolutionary history.
For the purpose of this thesis, these hypotheses take the form of one or more time-calibrated, bifurcating, labeled, rooted phylogenetic trees (frequently simply called a tree).
While the development of these models was not part of my PhD work, it is still useful to review the specific theory that underpins the analyses presented in the chapters of the thesis.

While trees represent a very powerful data structure to describe inferred evolutionary relationships, they are not always an intuitive structure to ``read.''
Figure~\ref{fig:treeDiagram} illustrates a hypothetical tree that describes a possible evolutionary relationship between three sequences, named \textit{A}, \textit{B}, and \textit{C}, and represented on the diagram by points.
By convention, such tree diagrams have a horizontal axis on which ranges from the past on the left to the present on the right.
Throughout this thesis, these sequences will interchangeably be referred to as \textbf{taxa} (singular: \textbf{taxon}), \textbf{tips}, or \textbf{leaves}.
Each taxon has a single \textbf{edge} (or \textbf{branch}) leading into it, where the length of the branch represents distance---either evolutionary or time.
When to branches merge together, the internal \textbf{node} on the tree where they meet represents the inferred most recent common ancestor (\gls{mrca}) of the set of taxa.
We call the subtree that descends from an internal node a \textbf{clade}.
For example, node \textit{ac} represents the inferred \gls{mrca} of taxa \textit{A} and \textit{B} occurring at $time=2$.
Each internal node then has its own branch in turn.
We refer to the \gls{mrca} of the entire set of taxa as the \textbf{root} of the tree. 

\begin{figure}[ht]
  \centering
  \includegraphics[width=.6\textwidth]{treeDiagram}
  \caption[Example phylogenetic tree]{A simple phylogenetic tree showing a hypothetical relationship between three taxa (\textit{A}, \textit{B}, and \textit{C}).
  }
  \label{fig:treeDiagram}
\end{figure}

Importantly (and often confusingly), it should be noted that both the vertical axis and the vertical lines in the tree diagram do not contain any meaningful information!
They only exist for visual clarity.
As such, any rotations about an internal node (e.g. if the clade containing taxa \textit{A} and \textit{B} were moved to the bottom of the tree and the branch to \textit{C} to the top) do not change the interpretation of the tree in any way.
Similarly, because the vertical axis does not carry information, when we want to calculate how much distance separates two taxa we only want to consider the sum of the horizontal branches that connect them, so the total distance that separates \textit{A} and \textit{B} is just the sum of the two branches that lead from \textit{ac} to \textit{A} ($l_A=1$) and \textit{B} ($l_B=2$), so the total distance between these two sequences is $l_A + l_B = 3$.

\subsection{Phylogenetic inference}
The theoretical core of all phylodynamic analysis concerns how can we infer a tree that accurately describes a observed set of related genomic sequences.
There are many ways by which one could judge how well a tree describes a observed set of taxa---some try to minimize the number of mutations that are necessary along the tree to produce the observed sequences, others attempt to find the tree that optimize all pairwise genetic distances between sequences---however the current gold standard for this task is to calculate phylogenetic \textit{tree likelihoods} under a continuous-time Markov chain (\gls{ctmc}) model of nucleotide evolution.
By using such models we have a principled method by which we can compare trees, regardless of how similar or dissimilar they are.

\subsubsection{Nucleotide evolution}
The backbone of phylogenetic likelihood calculation lies in modeling the nucleotide mutation process as a continuous-time Markov chain.
These models describe the instantaneous relative rates of mutations between nucleotides (A,C,G,T) described by a four-by-four matrix: $\mathbf{Q}$ where $\mathbf{Q}_{ij}$ is the relative mutation rate from nucleotide $i$ to nucleotide $j$.
Under such \gls{ctmc} models, each $\mathbf{Q}_{ij}$ can be thought of as the product of a model-specific rate parameter $\xu_{ij}$ and the equilibrium nucleotide frequency of the nucleotide that results from the mutation ($\pi_j$).
As an example, if we are interested in the relative instantaneous rate of mutation from $A \implies G$, we define:
\begin{equation}
  \mathbf{Q}_{AG} = \xu_{AG} \times \pi_G.
\end{equation}

For mathematical stability, $\mathbf{Q}$ defines the diagonal entries (corresponding to the rate at which a nucleotide mutates to the same nucleotide) are the negative sum of the rest of the row.

The most simple of these models was proposed by \citet{jukes1969evolution} (JC69), and models all relative rates with a single rate parameter, $\lambda$, and all equilibrium frequencies are equal ($\pi_A = \pi_C = \pi_G = \pi_T = .25$).
The most complex of these models that is generally used is called the generalized time-reversible (GTR) model \citep{tavare1986some}, which models each of the twelve potential mutations is allowed its own parameter, and all equilibrium frequencies are also allowed their own values.
Models with more parameters have a tendency to more accurately describe data, however this comes at the cost of computational complexity (resulting in longer runtimes) and risk that the data do not contain enough information to avoid model overfitting.
To strike an appropriate balance between model fit and complexity most analyses described in this thesis use the Hasegawa-Kishino-Yano (\gls{hky}) \citep{hasegawa1985dating}, which uses one rate ($\xu_I$) for transitions ($A \iff G$ and $C \iff T$), and another rate ($\xu_{II}$) for transversions ($A \iff C$, $A \iff T$, $G \iff C$, and $G \iff T$).
The \gls{hky} model allows each equilibrium frequency to have its own value.

\subsubsection{Phylogenetic likelihood}
Using the \gls{ctmc} model of nucleotide evolution, we can then define the \textbf{phylogenetic likelihood} for the chosen model: a function $\mathcal{L}$ that quantifies how well a given set of parameters for that model describe the data that we have observed.

We say that a tree ($\mathcal{T}$), as a combination of its topology ($\tau$) and a vector of its branch lengths ($\mathbf{\nu}$).
We call our dataset of $N$ aligned genomic sequences $\mathbf{X} = {x_1, x_2, \dots, x_N}$.
Because all sequences have the same length, $M$, we also consider the observed data by the site patterns found at the same position ($m \in M$) in all sequences, $\mathbf{X}^m$.

\clearpage
Consider the following hypothetical alignment of four sequences, each five nucleotides long:\\
\verb|ACGT|\\
\verb|ACGT|\\
\verb|ACGT|\\
\verb|CCGT|\\

If this alignment represented our observed data $\mathbf{X}$, then the first site pattern would be: $\mathbf{X}^1 = (A, A, A, C)$.

Under the \gls{ctmc} model of nucleotide evolution, we can calculate a probability of observing a particular site pattern $\mathbf{X}^m$, given a tree: $\mathbb{P}(\mathbf{X}^m | \tau, \mathbf{\nu})$.
While the exact calculation of this likelihood is not the focus of this thesis, conceptually it assigns probabilities to each branch of the tree based on their length and the transition rate matrix, and integrates over all possible ancestral states at internal nodes to assign a probability that a particular tree produced the observed data at its leaves.

Because of the critical assumption that all sites in the genome evolve independently, we are able define our phylogenetic likelihood for a tree given our observed data as the product of the probabilities at all sites:
\begin{equation}\label{eq:likelihood}
  \mathcal{L}(T | \mathbf{X}) = \prod_{m=1}^M \mathbb{P}(\mathbf{X}^m | \tau, \mathbf{\nu}). 
\end{equation}

This likelihood calculation can be expanded upon to include additional features of interest (correlations between mutations and time, models of demography, models of geographic dispersal, etc.); such extensions are the topic of Sections~\ref{ssec:molClock},~\ref{ssec:phylodynamics},~\&~\ref{ssec:phylogeography}.
The key function of the likelihood is that it allows us a principled manner by which we can compare two different trees which might describe the data that we observe, and to ask, ``which of these two trees is most likely to have generated the data?''

\subsubsection{Inferring phylogenies}
With a phylogenetic likelihood in hand, it is finally possible to explore methods by which we can infer a phylogeny and model parameters that best describes a set of sequences.
To accomplish this task there are two main statistical frameworks under which we can operate: maximum likelihood (ML), and Bayesian inference.

Both of these frameworks assume that we are able to generate an initial parameterization of a phylogenetic model: $\Psi = (\tau, \mathbf{\nu}, \mathbf{\Theta})$, where $\mathbf{\Theta}$ includes values for all of the parameters in the model (e.g. substitution rate matrix $\mathbf{Q}$).
Both frameworks then use some method of updating these parameters (referred to as \textbf{transition kernels} or \textbf{operators}), going from $\Psi$ to the updated $\Psi^{\prime}$ by tweaking one (or more) of the tree topology, branch lengths, or model parameters slightly.
It is important to note that both ML and Bayesian inference methodologies make use of the exact same likelihood functions and transition kernels, they differ primarily in how they calculate and describe the optimal phylogeny and model parameters.

\paragraph*{Maximum likelihood inference.}
Maximum likelihood inference, as the name suggests, seeks to estimate the set of parameters $\hat{\Psi}$ for which the phylogenetic likelihood is maximized---the values for each model parameter that best explain the data.
We call $\hat{\Psi}$ the maximum likelihood estimate (MLE) of model parameters, given the dataset:
\begin{equation}
  \hat{\Psi} = \argmax_{\tau,\mathbf{\nu},\mathbf{\Theta}} \mathcal{L}(\tau, \mathbf{\nu},\mathbf{\Theta} | \mathbf{X}).
\end{equation}

The key features of ML phylogenetic inference are that they are \textit{fast} and provide an \textit{easy-to-interpret} estimate of the best model parameters.

\paragraph*{Bayesian inference.}
In contrast to maximum likelihood phylogenetic inference, Bayesian inference differs in two key conceptual areas.
Bayesian inference supposes that in addition to information included in data, by including prior knowledge about a system we may improve our estimates about that system, particularly in cases where data are limited.
The results of Bayesian inference then describe not only the best single estimate of which parameter best describes the data, but also the uncertainty associated with that estimate.

For example, if one were interested in describing the average height of adults in Belgium, they may go and measure the heights of several people found on the street.
If they were performing maximum likelihood inference, simply calculating the mean and variance of the heights would be sufficient.
The Bayesian, by contrast, may both have a prior idea that the heights might be normally distributed around an average of 170cm.
After sampling they may update this estimate based on their observations, but the prior would still be incorporated.
This incorporation of prior information allows them to account for the possibility that they may only sample heights outside of a contrived bar catering only to professional basketball players and horse jockeys, which may result in a biased estimation.

To formalize these ideas, we make use of Bayes' theorem:
\begin{equation}
  \mathbb{P}(H|D) = \frac{\mathbb{P}(D|H) \times \mathbb{P}(H)}{\mathbb{P}(D)}.
\end{equation}
Put into English, this states that the probability of some hypothesis, $H$, given some data $D$ ($\mathbb{P}(H|D)$; called the \textit{posterior}) is proportional to the probability of the data given the hypothesis ($\mathbb{P}(D|H)$) and the probability of hypothesis itself ($\mathbb{P}(H)$).
We refer to these terms as the \textit{likelihood} and \textit{prior}, respectively.
Bayes' theorem also states that the posterior is inversely proportional to the overall probability of the data ($\mathbb{P}(D)$), called the \textit{marginal likelihood} term.

Adapting this framework into our phylogenetic context, we get:
\begin{equation}
  \mathbb{P}(\Psi|\mathbf{X}) = \frac{\mathbb{P}(\mathbf{X}|\Psi) \times \mathbb{P}(\Psi)}{\mathbb{P}(\mathbf{X})}.
\end{equation}
This equation can be expanded in part by substituting our phylogenetic likelihood from Equation~\ref{eq:likelihood}.
As it is quite difficult to assign a joint prior distribution to all model parameters, we instead also treat this as the product of priors on all model parameters.

The final consideration is to calculate the marginal likelihood term, which represents the probability of observing the data.
We can calculate this term by computing:
\begin{equation}
  \label{eq:marginalTerm}
  \mathbb{P}(\mathbf{X}) = \sum_{k=1}^{\zeta} \mathbb{P}(\mathbf{X}|\tau_k)\mathbb{P}(\tau_k).
\end{equation}
This represents a discrete integral over all possible tree topologies that could have generated the sequence data that we observe ($\zeta$ represents the number of all such topologies).

Our final equation that describes our posterior estimates of the model parameters given the data that we have observed is:
\begin{equation}
  \label{eq:posteriorLikelihood}
  \mathbb{P}(\Psi|\mathbf{X}) = 
    \frac{\mathcal{L}(\tau,\mathbf{\nu},\mathbf{\Theta}|\mathbf{X}) \times \mathbb{P}(\tau)\mathbb{P}(\mathbf{\nu})\mathbb{P}(\mathbf{\Theta})}
    {\sum_{k=1}^{\zeta} \mathbb{P}(\mathbf{X}|\tau_k)\mathbb{P}(\tau_k)}.
\end{equation}

This formulation ends up being extremely time consuming to compute compared to MLE (where ML analysis could take hours, Bayesian inference may take days or weeks), however the benefits of both including prior information and quantifying uncertainty make Bayesian phylogenetic analysis more robust in situations where time and computational resources allow it.

\paragraph*{Which should I use?}
This thesis uses both ML and Bayesian phylogenetic inference for different tasks.
Because of its speed and clarity, ML analyses were used for the entirety of Chapter~\ref{ch:chapter1}, as the time constraint of real-time analysis made Bayesian inference impossible.
Additionally, ML analyses prove extremely useful for preliminary analyses of datasets, when quick insights are useful for deciding how to formulate a larger-scale Bayesian inference later, as is shown in Chapter~\ref{ch:chapter2}.
Generally, Bayesian phylogenetic inference proves to be better when time is not extremely constrained, and is therefore the main methodology used in Chapters~\ref{ch:chapter2}~\&~\ref{ch:chapter3}.
The ability to quantify uncertainty allows us to not only make inferences, but also to speak about how confident we are in those inferences.
Additionally, the ability to inject prior information into an analysis proves extremely useful in cases where the data do not provide sufficient signal to infer particular parameters---this is crucial to the analysis shown in Chapter~\ref{ch:chapter3}.

\subsection{Temporal resolution and the molecular clock}\label{ssec:molClock}
While the \gls{ctmc} model of nucleotide evolution underpins all phylogenetic models by giving us a way to infer trees with branch lengths from genomic sequence data, there are numerous categories of models that allow us to infer epidemiologically relevant traits from our datasets.
One such category---referred to as \textbf{molecular clock} models---consider the mutation process as a function of time, thereby re-scaling phylogenies to have branches whose lengths represent time rather than genetic distances (Fig.~\ref{fig:phylogeneticsOverview}b).
In doing so, we can consider \textit{when in history} the \gls{mrca} of a set of sequences existed, which proves useful when trying to understand how a disease has spread through time.

\subsubsection{Setting a molecular clock}
Generally, there are three main ways that a molecular clock can be assigned to a phylogeny.
The most simple of these is to know the evolutionary rate of the phylogeny \textit{a priori}---this is frequently the case for well-characterized pathogens such as \gls{sarscov2}.
In such cases, one can apply the known clock rate to their pathogen of interest.
The second method leverages \textit{a priori} knowledge slightly differently, but to a similar effect.
In cases where a known split present in the the phylogeny occurred at a known time, it is possible to calibrate a clock model based on knowing how far in the past that ``calibration point'' took place.
This can be used when the phylogeny spans such distant past that the fossil record gives an estimate for a known divergence time.
In the case of viral phylodynamics, it is quite rare for ancestral lineage divergences to be well characterized in a way that makes this method particularly useful.
The primary method of molecular clock modeling used in this thesis involves the estimation of a molecular clock directly from time-stamped sequence data.

\paragraph*{Measurably evolving populations.}
In cases we are able to collect genomes from a group of organisms over the same time period that their evolution is taking place, that is said to be a measurably evolving population (\gls{mep}).
One scenario that can result in a \gls{mep} is when bodies from that population have been well preserved (e.g. in permafrost) for enough of their evolutionary history that we can extract genetic material from the mummies \citep{shapiro2004rise}.
The other main scenario where we observe \gls{mep}s comes when organisms (such as RNA viruses) evolve so quickly that we are able to observe evolution taking place at the same time scale as the epidemic itself.

\paragraph*{Temporal signal.}
If a dataset contains sufficient information to accurately fit a molecular clock, it is said to have \textit{temporal signal}.
A standard preliminary analysis to assess whether a dataset contains sufficient temporal signal involves taking a rooted ML tree of the dataset with branch lengths measured in genetic distance and associated dates.
Each tip can then be plotted as a function of its root-tip total divergence against time.
If the dataset demonstrates strong temporal signal, this scatter plot will be well-fit by a linear regression whose slope describes its evolutionary rate (substitutions per site per unit time), and its x-intercept will represent an estimate for its \gls{tmrca}.

\paragraph*{Clock models.}
The analyses in this thesis use different types of clock models.
For the real-time ML analyses, we use a model known as a strict clock.
Under this model, one clock rate governs all branches in the tree, representing an expectation that evolution takes place at the same average rate across the entire evolutionary history.
By contrast, the Bayesian phylodynamic analyses use a relaxed clock model, wherein each branch of the tree is considered a draw from an underlying probability distribution (generally a lognormal distribution).

\subsection{Phylodynamics and genomic epidemiology}\label{ssec:phylodynamics}
Beyond the evolutionary dynamics of a virus, it is possible to infer some of the underlying epidemiological features of a virus from its phylogeny.
Among these include an estimate of the viruses underlying demography (i.e. population structure through time), as well as how it has been spreading through space and time.

\paragraph*{The coalescent.}
The branching patterns and expected branch lengths of trees are correlated to the underlying population structure of the viruses they represent.
Generally, we expect to observe more rapid branching (and therefore shorter expected branch lengths) in smaller populations, and longer branches in trees from larger populations (Fig.~\ref{fig:coalescentOverview}).
This relationship is defined under a backwards-in-time model known as the coalescent \citep{kingman1982coalescent,kingman1982genealogy}.
Under this model, any two individuals have an equal probability of ``choosing'' any individual from the previous generation as their ancestor, so the probability that any two choose the same ancestor is inversely proportional to the size of the population.
This leads lineages moving backwards through time to \textit{coalesce} more quickly in small populations and more slowly in large populations.
If we invert this relationship, we can infer that periods of time where a phylogeny has many branching events (i.e. coalescences) come from a smaller population, and times with fewer branching events from larger populations.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.95\textwidth]{coalescent_schematic}
  \caption[Demography effects tree shape]{Illustrations of three tree structures expected under different coalescent models; each examples includes both an illustration of the generative coalescent process under a different population size model where dots represent individuals and lines represent parent/child relationships, a subsample of those relationships are highlighted in blue. Below each coalescent plot is the observed tree shape generated by that process. \textit{(left)} Constant population size over time: we expect relatively short branches near the present, and longer branches toward the past. \textit{(center)} Exponentially growing population: we expect longer branches near the present and relatively shorter branches in the past. \textit{(right)} Population with a bottleneck: we expect very short branches at the time of the bottleneck, and very long branches further back in time.
  }
  \label{fig:coalescentOverview}
\end{figure}

Under this framework, we are able to not only define some sort of prior on tree shapes based known epidemiological information, but also we are able to independently derive epidemiological features such as $R_0$ independently from case count data.

\subsection{Phylogeography}\label{ssec:phylogeography}
Phylogeographic analysis provides a framework for understanding how pathogens move through space and time by integrating geographic information into phylogenetic inference.
By considering the locations from which sequences were sampled as traits that can be mapped onto a phylogeny, we can reconstruct the geographic history of viral lineages.
This approach has proven particularly valuable in understanding the emergence and spread of viral pathogens across different spatial scales, from local transmission chains to global pandemics.

\subsubsection{Reconstructing spatiotemporal spread}
The primary goal of phylogeographic analysis is to answer fundamental questions about pathogen movement and establishment.
Perhaps the most basic of these questions concerns the geographic origin of a pathogen: where did it first emerge, and from where did it spread to other locations?
This origin question is particularly relevant for emerging infectious diseases, where identifying the source location can inform both prevention strategies and our understanding of zoonotic spillover events.
A second key question addresses the timing of pathogen introduction into specific locations: when did the pathogen first arrive in a given area, and how does this timing relate to the first detected cases?
Finally, phylogeographic methods can reveal the number and timing of separate introduction events into a location, helping us understand whether an outbreak represents a single introduction followed by local transmission, or multiple independent introductions from different sources.
These patterns of introduction and establishment are crucial for understanding both historical epidemics and preparing for future outbreaks.

\subsubsection{Discrete phylogeographic models}
While it is possible to consider viral locations as a continuous trait that moves through space, it is often more helpful to consider discrete geographic locations (zip codes, countries, continents) instead (Fig.~\ref{fig:phylogeneticsOverview}d).
By treating location as a discrete trait we can both infer migrations between units that are politically and socially relevant---helping for public health communication and intervention---as well as simplifying the computational burden of the analysis.

\paragraph*{CTMC model of geographic dispersal in discrete space.}
The mathematical framework for discrete phylogeographic inference parallels that of nucleotide evolution, employing a continuous-time Markov chain model to describe transitions between geographic states.
Just as the $\mathbf{Q}$ matrix in nucleotide models describes instantaneous rates of mutation between different nucleotides, in phylogeography it describes rates of movement between different locations.
Each element, $\mathbf{Q}_{ij}$, represents the rate at which lineages transition from location $i$ to location $j$.
This mathematical equivalence allows us to leverage the same likelihood calculation machinery used in sequence evolution models, treating geographic locations as discrete character states evolving along the branches of the phylogeny.

\paragraph*{Statistical power and overcoming sampling bias.}
A significant challenge in phylogeographic inference arises from sampling bias, as the number of sequences available from different locations rarely reflects the true underlying prevalence of the pathogen in those areas.
More economically developed regions often contribute disproportionately more sequences to global databases, while regions with limited surveillance capacity may be underrepresented despite having significant disease burden.
To address this bias, studies often employ strategic subsampling of over represented regions to create more balanced datasets.
This approach helps prevent the overestimation of certain migration routes simply due to sampling intensity, though care must be taken to ensure that important evolutionary or epidemiological signals are not lost in the process.
The choice of subsampling strategy can significantly impact the resulting phylogeographic inference, making it crucial to carefully consider and document these choices in any analysis.

% 1.4
\section{Phylodynamics: from theory to practice}
The theoretical frameworks described in the previous section are implemented through several key software packages that enable practical phylodynamic analysis.
This thesis employs different computational approaches depending on the specific requirements of each analysis, particularly whether speed or accuracy is the primary concern.

\subsection{Real-time phylodynamics}
The demands of real-time phylodynamic analysis during disease outbreaks necessitate rapid computational approaches that can process new sequence data and generate results within timeframes relevant for public health decision-making.
While Bayesian methods provide more comprehensive uncertainty quantification, their computational intensity makes them impractical for scenarios where results are needed within hours of sequence generation.
Maximum likelihood methods, though less thorough in their exploration of parameter space, offer a pragmatic solution to this time-sensitivity problem by providing rapid, point estimates of evolutionary relationships and model parameters.

\subsubsection{Maximizing phylogenetic likelihood}
Recall that maximum likelihood analysis seeks to find the tree, branch lengths, and model parameters that result in the highest likelihood score.
How this maximum likelihood estimate is calculated in practice is conceptually similar to the idea of climbing a hill to reach its peak.
From wherever on the hillside that we begin, we may consider a step in any direction of our choice.
If that step would take us to a higher elevation, we take the step; if the step would take us to a lower or the same elevation, we don't take the step and try again.
Eventually, we will reach a point where we can no longer find a direction from which we can step uphill anymore.

We apply this same algorithm to maximum likelihood estimation: given an initial set of parameters, $\Psi$, we can apply a transition kernel to generate a modified parameter set, $\Psi^{\prime}$, which we call the \textit{proposal}.
We can then compare the likelihoods generated by the initial parameters ($\mathcal{L}(\Psi)$) and the proposal ($\mathcal{L}(\Psi^{\prime})$): if the proposal set generated a higher likelihood, then we update $\Psi$ to take the values of the proposal set, if the proposal set is less likely, we discard it and keep $\Psi$ the same.
We can then repeat this process until the algorithm is not able to generate a proposal that improves the likelihood.

There are many potential optimizations to this algorithm.
Within the hill climbing metaphor, one could seek to always take the steepest step uphill, vary their step length dynamically, or to try starting from different starting points on the hillside to see if they yield the same result.
While they are beyond the scope of this thesis, such optimizations and many others have been included in popular software packages that perform ML phylogenetic inference.

\subsubsection{Nextstrain}
The choice of Nextstrain \citep{hadfield2018nextstrain} as our primary platform for real-time SARS-CoV-2 phylodynamic analysis in Belgium was driven by several features that made it well-suited for pandemic response within Belgium.
At its core, Nextstrain provided a wrapper around established maximum likelihood phylogenetic software packages, including IQ-Tree2 \citep{minh2020iq}, with carefully curated default parameters optimized for SARS-CoV-2 analysis.
Nextstrain links alignment, phylogenetic inference, time-resolution, and phylogeographic inference in a sequential manner, with the result of each step given as the input to the next.
This conditional inference procedure results in it running extremely quickly, with results often coming within minutes or hours.

The integration of gold-standard phylogenetic tools, combined with automated quality control and alignment procedures, enabled rapid and reliable processing of new sequence data as it became available.
Furthermore, the Nextstrain team's simultaneous efforts in updating the platform throughout the pandemic proved very useful, as new lineage definitions and scaling tools were integrated as new variants emerged and datasets grew through the pandemic.

\subsection{Bayesian phylodynamics}
For the analyses presented in Chapters~\ref{ch:chapter2}~\&~\ref{ch:chapter3}, Bayesian inference was used, as its joint inference framework proves more robust when analyses are not under such a tight time constraint.
The key feature of Bayesian phylodynamic inference---as opposed to ML inference---is that Bayesian inference allows us to consider a \textit{posterior probability distribution} of all parameters, $\Phi = (\tau,\overline{\nu},\mathbf{\Theta})$.
This posterior probability distribution is described by Equation~\ref{eq:posteriorLikelihood}.
However, when performing analyses on real datasets, this calculation becomes computationally infeasible very quickly as datasets incorporate more sequences.

\paragraph*{Tree space.}
This computational intractability stems from the calculation of the marginal likelihood term, described in Equation~\ref{eq:marginalTerm}, which requires us to integrate over the space of all possible phylogenetic trees---an impossibly large number ($\zeta$).
Even ignoring potential branch lengths, the number of potential tree topologies relating $n$ sequences alone is incomprehensible, described by the equation:
\begin{equation}
  \label{eq:treeSpace}
  \frac{(2n-3)!}{2^{n-1}(n-1)!}.
\end{equation}
This number grows quickly, eclipsing the number of subatomic particles in the observable universe \citep{padilla2022fantastic} for topologies of just 29 taxa.
It is simply not possible to perform this computation for even modestly sized datasets.
Rather, we opt for an algorithm by which we can \textit{approximate the posterior distribution} by drawing samples from the posterior distribution proportionally to their posterior probability.
In doing so, we can simply summarize the sample to estimate the underlying posterior distribution.
The algorithm that allows us to do this---known as \textbf{Markov chain Monte Carlo} (\gls{mcmc})---achieves our goal by parameterizing the posterior probability distribution as a Markov chain, and leverages randomness to explore the posterior probability distribution.

\subsubsection{Markov chain Monte Carlo}
The algorithmic implementation of \gls{mcmc} uses the Metropolis-Hastings algorithm \citep{metropolis1953equation,hastings1970monte}.
For a conceptual understanding of this algorithm, let us recall (and abuse) the earlier hill-climbing metaphor.
Where before we sought to just climb a hill to its peak, we now wish to characterize all the peaks of a mountain range by logging the elevation (posterior phylogenetic likelihood) at our current point.
Also, we are blindfolded, so we don't know where we are going ahead of time.

To characterize the mountains, we know we will need to take steps both uphill (into higher likelihood space), as well as downhill occasionally, but we are interested in the peaks, so we treat them preferentially.
According to the Metropolis-Hastings algorithm, we mark down the elevation at our current point, then consider taking a random step in some direction, and measure the elevation of where we would land after the step.
If the step would take us uphill, we will always take that step.
If the step takes us downhill, then we are met with a choice: to take the step downhill, or to remain exactly where we are.
To help us make the choice we consider how much of a step downhill we would be taking, and randomly choose to take the step with probability proportional to how far downhill it will take us: if it would be an imperceptibly small step downhill we will almost certainly take the step, but if the step would throw us off of a cliff we probably choose to stay where we were.
By repeating this process for a very, very long time we will fully describe the peaks of the range (and have extremely tired feet).

To formalize this notion in a phylogenetic context, we begin with our starting parameters, $\Phi$, as well as a proposed modified set, $\Phi^{\prime}$, generated under the exact same type of transition kernel used in ML inference.
We can then define our \textit{acceptance ratio}, $\mathfrak{R}$---the probability that we take the step in parameter space:
\begin{equation}
  \mathfrak{R} = 
    min \left( 1, \frac{\mathbb{P}(\Psi^{\prime}|\mathbf{X})}
                       {\mathbb{P}(\Psi|\mathbf{X})} \times 
                         \frac{\mathbb{P}(\Psi|\Psi^{\prime})}
                              {\mathbb{P}(\Psi^{\prime}|\Psi)} \right).
\end{equation}
The rightmost term of this relationship accounts for potential asymmetry in the transition kernels, and is known as the \textit{Hastings ratio}; it is not conceptually important for the remaining description (just know that it can be computed easily), so we will simply call that term $h(\Psi,\Psi^{\prime})$.
The more crucial term represents the ratio of the proposed posterior probability to the posterior probability of the initial parameter set.
Expanding the posterior ratios according to Equation~\ref{eq:posteriorLikelihood}, we get:
\begin{equation}
  \mathfrak{R} =
    min \left( 1, \frac{\frac{\mathcal{L}(\Psi^{\prime}|\mathbf{X}) \mathbb{P}(\Psi^{\prime})}
                             {\mathbb{P}(\mathbf{X})}}
                       {\frac{\mathcal{L}(\Psi|\mathbf{X}) \mathbb{P}(\Psi)}
                             {\mathbb{P}(\mathbf{X})}}
                       \times h(\Psi,\Psi^{\prime}) \right).
\end{equation}
This expansion represents the crux of how \gls{mcmc} allows us to sample from the posterior distribution, as the incalculable marginal terms cancel out, and leave us with only terms that we can compute: the ratio of phylogenetic likelihoods, the ratio of prior probabilities, and the Hastings ratio:
\begin{equation}
  \mathfrak{R} =
    min \left( 1, \frac{\mathcal{L}(\Psi^{\prime}|\mathbf{X})}
                       {\mathcal{L}(\Psi|\mathbf{X})}
                  \times
                  \frac{\mathbb{P}(\Psi^{\prime})}
                       {\mathbb{P}(\Psi)}
                  \times
                  h(\Psi,\Psi^{\prime}) \right).
\end{equation}
So, $\mathfrak{R}$ will take a value of one if the product of ratios is greater than one (representing an ``uphill'' step in posterior probability space), and if the product is less than one $\mathfrak{R}$ will quantify how extreme of a drop in posterior probability the proposal parameter set yields.
Finally, we need only to generate a random number $y~U(0,1)$ and compare it to $\mathfrak{R}$; if $y < \mathfrak{R}$ we update our Markov chain such that $\Psi = \Psi^{\prime}$, otherwise it remains in its original state.
This process is then repeated until the entire posterior probability distribution has been thoroughly sampled.

\subsection{Effective sample size and burn-in}

Bayesian phylogenetic inference on complex datasets presents significant computational challenges, often requiring weeks or months of continuous computation to draw enough samples from the posterior distribution to draw conclusions from.
During analysis, the Markov chain is periodically sampled to record parameter states, with the quality of posterior exploration measured by the effective sample size (\gls{ess}).
The \gls{ess} quantifies the number of effectively independent samples drawn from the posterior distribution, accounting for the high correlation between sequential draws from the posterior.
While there's no theoretical minimum \gls{ess} value, a threshold of 200 is commonly used as a practical balance between computational investment and sampling adequacy.
A significant portion of computation time is devoted to the initial ``burn-in'' period, during which the rapidly moves parameters from their starting value into high posterior probability space.
This burn-in phase, which must be discarded from the final analysis, presents a particular challenge for computational efficiency, as it can only be shortened through strongly informative priors or more efficient transition kernels.
Consequently, even parallel chains must each undergo their own burn-in period, limiting the benefits of parallel computation.

\subsection{BEAST}
Bayesian phylogenetic analyses in this thesis are conducted using \gls{beast} (Bayesian Evolutionary Analysis Sampling Trees) version 1.10 \citep{suchard2018bayesian}, a software package that combines sophisticated evolutionary models with practical usability.
\gls{beast} implements a wide range of evolutionary models, prior distributions, and transition kernels that have been optimized for efficient analysis of large genomic datasets. 
The software's practical utility is enhanced by the BEAGLE \citep{ayres2019beagle} hardware optimization library and an extensive suite of auxiliary tools that facilitate parallel computation and results interpretation, making it well-suited for both high-performance computing clusters.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file,
% otherwise \includeonly includes empty pages.
\cleardoublepage

% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}
